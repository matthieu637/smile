
@BOOK{PDMIA,
author={{Groupe PDMIA}},
year = 2008,
title="Processus DÃ©cisionnels de Markov en intelligence artificielle",
publisher= "Laboratoire Informatique Paris 6, Equipe MAIA - INRIA (LORIA)"
}

@BOOK{ReinforceLearningIntro,
author= "Sutton, Richard S and Barto, Andrew G",
year = 1998,
title="Reinforcement Learning : An Introduction",
publisher= "MIT Press",
address="Cambridge, MA"
}

@BOOK{IntArt,
title = "Intelligence Artificielle",
year = 2006,
author = "Stuart Russell and Peter Norvig",
publisher= "PEARSON Education",
}


#START passive learning
#---------------

@inproceedings{Russell:1998:LAU:279943.279964,
 author = {Russell, Stuart},
 title = {Learning agents for uncertain environments (extended abstract)},
 booktitle = {Proceedings of the eleventh annual conference on Computational learning theory},
 series = {COLT' 98},
 year = {1998},
 isbn = {1-58113-057-0},
 location = {Madison, Wisconsin, USA},
 pages = {101--103},
 numpages = {3},
 url = {http://doi.acm.org/10.1145/279943.279964},
 doi = {10.1145/279943.279964},
 acmid = {279964},
 publisher = {ACM},
 address = {New York, NY, USA},
}


@inproceedings{Ng:2000:AIR:645529.657801,
 author = {Ng, Andrew Y. and Russell, Stuart J.},
 title = {Algorithms for Inverse Reinforcement Learning},
 booktitle = {Proceedings of the Seventeenth International Conference on Machine Learning},
 series = {ICML '00},
 year = {2000},
 isbn = {1-55860-707-2},
 pages = {663--670},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=645529.657801},
 acmid = {657801},
 publisher = {Morgan Kaufmann Publishers Inc.},
 address = {San Francisco, CA, USA},
}

@inproceedings{Abbeel:2004:ALV:1015330.1015430,
 author = {Abbeel, Pieter and Ng, Andrew Y.},
 title = {Apprenticeship learning via inverse reinforcement learning},
 booktitle = {Proceedings of the twenty-first international conference on Machine learning},
 series = {ICML '04},
 year = {2004},
 isbn = {1-58113-838-5},
 location = {Banff, Alberta, Canada},
 pages = {1--},
 url = {http://doi.acm.org/10.1145/1015330.1015430},
 doi = {10.1145/1015330.1015430},
 acmid = {1015430},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@article{ramachandran2007bayesian,
  title={Bayesian inverse reinforcement learning},
  author={Ramachandran, Deepak and Amir, Eyal},
  journal={Urbana},
  volume={51},
  pages={61801},
  year={2007}
}

#END passive learning
#--------------------
#START supervised learning

@inproceedings{grollman2007dogged,
  title={Dogged learning for robots},
  author={Grollman, Daniel H and Jenkins, Odest Chadwicke},
  booktitle={Robotics and Automation, 2007 IEEE International Conference on},
  pages={2483--2488},
  year={2007},
  organization={IEEE}
}


@article{chernova2009interactive,
  title={Interactive policy learning through confidence-based autonomy},
  author={Chernova, Sonia and Veloso, Manuela},
  journal={Journal of Artificial Intelligence Research},
  volume={34},
  number={1},
  pages={1},
  year={2009}
}

@inproceedings{amit2002learning,
  title={Learning movement sequences from demonstration},
  author={Amit, Ramesh and Matari, Maja},
  booktitle={Development and Learning, 2002. Proceedings. The 2nd International Conference on},
  pages={203--208},
  year={2002},
  organization={IEEE}
}


@article{syed2010reduction,
  title={A reduction from apprenticeship learning to classification},
  author={Syed, Umar and Schapire, Robert E},
  journal={Advances in Neural Information Processing Systems (NIPS-23)},
  pages={2253--2261},
  year={2010},
  publisher={Citeseer}
}


@inproceedings{Morales:2004:LFC:1015330.1015384,
 author = {Morales, Eduardo F. and Sammut, Claude},
 title = {Learning to fly by combining reinforcement learning with behavioural cloning},
 booktitle = {Proceedings of the twenty-first international conference on Machine learning},
 series = {ICML '04},
 year = {2004},
 isbn = {1-58113-838-5},
 location = {Banff, Alberta, Canada},
 pages = {76--},
 url = {http://doi.acm.org/10.1145/1015330.1015384},
 doi = {10.1145/1015330.1015384},
 acmid = {1015384},
 publisher = {ACM},
 address = {New York, NY, USA},
} 

@inproceedings{Chernova:2007:CPL:1329125.1329407,
 author = {Chernova, Sonia and Veloso, Manuela},
 title = {Confidence-based policy learning from demonstration using Gaussian mixture models},
 booktitle = {Proceedings of the 6th international joint conference on Autonomous agents and multiagent systems},
 series = {AAMAS '07},
 year = {2007},
 isbn = {978-81-904262-7-5},
 location = {Honolulu, Hawaii},
 pages = {233:1--233:8},
 articleno = {233},
 numpages = {8},
 url = {http://doi.acm.org/10.1145/1329125.1329407},
 doi = {10.1145/1329125.1329407},
 acmid = {1329407},
 publisher = {ACM},
 address = {New York, NY, USA},
 keywords = {imitation, learning from demonstration, robotics},
} 


#END supervised learning
#----------------------------------------------------------
#START active learning

@incollection{lopes2009active,
  title={Active learning for reward estimation in inverse reinforcement learning},
  author={Lopes, Manuel and Melo, Francisco and Montesano, Luis},
  booktitle={Machine Learning and Knowledge Discovery in Databases},
  pages={31--46},
  year={2009},
  publisher={Springer}
}


@inproceedings{cohn2011comparing,
  title={Comparing action-query strategies in semi-autonomous agents},
  author={Cohn, Robert and Durfee, Edmund and Singh, Satinder},
  booktitle={The 10th International Conference on Autonomous Agents and Multiagent Systems},
  volume={3},
  pages={1287--1288},
  year={2011}
}

#END active learning
#----------------------------------------
#START survey

@article{Argall:2009:SRL:1523530.1524008,
 author = {Argall, Brenna D. and Chernova, Sonia and Veloso, Manuela and Browning, Brett},
 title = {A survey of robot learning from demonstration},
 journal = {Robot. Auton. Syst.},
 issue_date = {May, 2009},
 volume = {57},
 number = {5},
 month = may,
 year = {2009},
 issn = {0921-8890},
 pages = {469--483},
 numpages = {15},
 url = {http://dx.doi.org/10.1016/j.robot.2008.10.024},
 doi = {10.1016/j.robot.2008.10.024},
 acmid = {1524008},
 publisher = {North-Holland Publishing Co.},
 address = {Amsterdam, The Netherlands, The Netherlands},
 keywords = {Autonomous systems, Learning from demonstration, Machine learning, Robotics},
} 

@article{Taylor:2009:TLR:1577069.1755839,
 author = {Taylor, Matthew E. and Stone, Peter},
 title = {Transfer Learning for Reinforcement Learning Domains: A Survey},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2009},
 volume = {10},
 month = dec,
 year = {2009},
 issn = {1532-4435},
 pages = {1633--1685},
 numpages = {53},
 url = {http://dl.acm.org/citation.cfm?id=1577069.1755839},
 acmid = {1755839},
 publisher = {JMLR.org},
} 

@article{settles2010active,
  title={Active learning literature survey},
  author={Settles, Burr},
  journal={University of Wisconsin, Madison},
  year={2010}
}

@misc{zhu2005semi,
  title={Semi-supervised learning literature survey},
  author={Zhu, Xiaojin},
  year={2005},
  publisher={Citeseer}
}


#END survey
#-----------------------------------------
#START Game theory

@ARTICLE{2012arXiv1206.3261H,
   author = {{Hines}, G. and {Larson}, K.},
    title = "{Learning When to Take Advice: A Statistical Test for Achieving A Correlated Equilibrium}",
  journal = {ArXiv e-prints},
archivePrefix = "arXiv",
   eprint = {1206.3261},
 primaryClass = "cs.GT",
 keywords = {Computer Science - Computer Science and Game Theory, Computer Science - Artificial Intelligence, Computer Science - Multiagent Systems},
     year = 2012,
    month = jun,
   adsurl = {http://adsabs.harvard.edu/abs/2012arXiv1206.3261H},
  adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

#END active learning
#-----------------------------------------
#START TUTOR IS A AGENT

@inproceedings{Torrey:2013:TBA:2484920.2485086,
 author = {Torrey, Lisa and Taylor, Matthew},
 title = {Teaching on a budget: agents advising agents in reinforcement learning},
 booktitle = {Proceedings of the 2013 international conference on Autonomous agents and multi-agent systems},
 series = {AAMAS '13},
 year = {2013},
 isbn = {978-1-4503-1993-5},
 location = {St. Paul, MN, USA},
 pages = {1053--1060},
 numpages = {8},
 url = {http://dl.acm.org/citation.cfm?id=2484920.2485086},
 acmid = {2485086},
 publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
 address = {Richland, SC},
 keywords = {advice taking, agent teaching, reinforcement learning},
} 

@INPROCEEDINGS{Thrun96learningto,
    author = {S. Thrun},
    title = {Learning To Learn: Introduction},
    booktitle = {In Learning To Learn},
    year = {1996},
    publisher = {Kluwer Academic Publishers}
}

#END
#--------------------------
#START FURTHER

@article{dietterich1999hierarchical,
  title={Hierarchical reinforcement learning with the MAXQ value function decomposition},
  author={Dietterich, Thomas G},
  journal={arXiv preprint cs/9905014},
  year={1999}
}

@article{Ghavamzadeh:2007:HAR:1314498.1390329,
 author = {Ghavamzadeh, Mohammad and Mahadevan, Sridhar},
 title = {Hierarchical Average Reward Reinforcement Learning},
 journal = {J. Mach. Learn. Res.},
 issue_date = {12/1/2007},
 volume = {8},
 month = dec,
 year = {2007},
 issn = {1532-4435},
 pages = {2629--2669},
 numpages = {41},
 url = {http://dl.acm.org/citation.cfm?id=1314498.1390329},
 acmid = {1390329},
 publisher = {JMLR.org},
}

@article{Konidaris:2012:TRL:2188385.2343689,
 author = {Konidaris, George and Scheidwasser, Ilya and Barto, Andrew},
 title = {Transfer in Reinforcement Learning via Shared Features},
 journal = {J. Mach. Learn. Res.},
 issue_date = {3/1/2012},
 volume = {13},
 month = jun,
 year = {2012},
 issn = {1532-4435},
 pages = {1333--1371},
 numpages = {39},
 url = {http://dl.acm.org/citation.cfm?id=2188385.2343689},
 acmid = {2343689},
 publisher = {JMLR.org},
} 

#END



@inproceedings{semi1,
title = "Policy invariance under reward transformations: Theory and application to reward shaping",
author = "Andrew Y. Ng and Daishi Harada and Stuart Russell",
year = 1999,
booktitle = "Proceedings of the Sixteenth International Conference on Machine Learning"
}



@inproceedings{greenwald2003correlated,
  title={Correlated Q-learning},
  author={Greenwald, Amy and Hall, Keith and Serrano, Roberto},
  booktitle={MACHINE LEARNING-INTERNATIONAL WORKSHOP THEN CONFERENCE-},
  volume={20},
  number={1},
  pages={242},
  year={2003}
}

@article{Choi:2011:IRL:2021026.2021028,
 author = {Choi, Jaedeug and Kim, Kee-Eung},
 title = {Inverse Reinforcement Learning in Partially Observable Environments},
 journal = {J. Mach. Learn. Res.},
 issue_date = {7/1/2011},
 volume = {999999},
 month = jul,
 year = {2011},
 issn = {1532-4435},
 pages = {691--730},
 numpages = {40},
 url = {http://dl.acm.org/citation.cfm?id=2021026.2021028},
 acmid = {2021028},
 publisher = {JMLR.org},
} 




#-----------------------------------------------------------------------------


